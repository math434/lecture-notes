{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floating-point arithmetic\n",
    "\n",
    "Real numbers are stored on a computer following the IEEE floating-point standard:\n",
    "\n",
    "1. **half precision** using 16 bits (Julia type: `Float16`)\n",
    "2. **single precision** using 32 bits (Julia type: `Float32`)\n",
    "3. **double precision** using 64 bits (Julia type: `Float64`)\n",
    "\n",
    "Julia also has an **arbitrary precision** floating-point data type called `BigFloat`. It is excellent if you need more precision, but it is also much slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Loading help data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataType   : FloatingPoint\n",
      "  supertype: Real\n",
      "  subtypes : {BigFloat,Float16,Float32,Float64}\n"
     ]
    }
   ],
   "source": [
    "?FloatingPoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of IEEE double floating-point format (`Float64`)\n",
    "\n",
    "Suppose $x$ is a floating-point number stored in the following 64-bits:\n",
    "\n",
    "| 1 | 2 | $\\cdots$ | 12 | 13 | $\\cdots$ | 64 |\n",
    "|:-:|:-:|:--------:|:--:|:--:|:--------:|:--:|\n",
    "|$s$|$e_{10}$| $\\cdots$ |$e_0$|$f_1$|$\\cdots$|$f_{52}$|\n",
    "\n",
    "- 1 bit $s$ represents the **sign**\n",
    "- 11 bits $e_{10} \\cdots e_{0}$ represent the **exponent**\n",
    "- 52 bits $f_1 \\cdots f_{52}$ represent the **fraction** (a.k.a. the mantissa or significand)\n",
    "\n",
    "Then\n",
    "\n",
    "$$ x = (-1)^s \\left[1.f_1 \\cdots f_{52}\\right]_2 \\times 2^{(e-1023)}.$$\n",
    "\n",
    "Notes: \n",
    "\n",
    "- $x$ is **normalized** to have its first digit nonzero.\n",
    "- $e = \\left[e_{10} \\cdots e_{0}\\right]_2 = e_{10} 2^{10} + \\cdots + e_1 2^1 + e_0 2^0 \\in \\left[0, 2^{11}-1\\right] = [0, 2047]$\n",
    "- $e = 0$ and $e = 2047$ are reserved for special floating-point values, so \n",
    "\n",
    "$$e \\in [1, 2046]$$\n",
    "\n",
    "- the \"$-1023$\" in the exponent is called the **bias**:  $e-1023 \\in [-1022,1023]$\n",
    "- $\\left[1.f_1 \\cdots f_{52}\\right]_2 = 1 + \\frac{f_1}{2^1} + \\frac{f_2}{2^2} + \\cdots + \\frac{f_{52}}{2^{52}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "x & = -[1.101101]_2 \\times 2^{(1026-1023)} \\\\\n",
    "  & = -[1.101101]_2 \\times 2^{3} \\\\\n",
    "  & = -[1101.101]_2 \\\\\n",
    "  & = -\\left(1 \\cdot 8 + 1 \\cdot 4 + 0 \\cdot 2 + 1 \\cdot 1 + 1 \\cdot \\frac{1}{2} + 0 \\cdot \\frac{1}{4} + 1 \\cdot \\frac{1}{8}\\right)  \\\\\n",
    "  & = -13.625\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base.bits(n)\n",
      "\n",
      "   A string giving the literal bit representation of a number.\n"
     ]
    }
   ],
   "source": [
    "?bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1100000000101011010000000000000000000000000000000000000000000000\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = -13.625\n",
    "bits(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1',\"10000000010\",\"1011010000000000000000000000000000000000000000000000\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = bits(x)[1]\n",
    "e = bits(x)[2:12]\n",
    "f = bits(x)[13:64]\n",
    "s, e, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1026"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(0b10000000010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Even if a number can be represented exactly in base-10 with a finite number of digits, it may require an infinite number of digits in base-2.\n",
    "\n",
    "$$\n",
    "0.1 = \\left[0.000110011001\\ldots\\right]_2 = \\left[1.\\overline{1001}\\right]_2 \\times 2^{-4}\n",
    "$$\n",
    "\n",
    "Therefore, $0.1$ cannot be represented exactly as a floating-point number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0',\"01111111011\",\"1001100110011001100110011001100110011001100110011010\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 0.1\n",
    "s = bits(x)[1]\n",
    "e = bits(x)[2:12]\n",
    "f = bits(x)[13:64]\n",
    "s, e, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(0b01111111011) - 1023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.000000000000000055511151231257827021181583404541015625e-01 with 256 bits of precision"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = big(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limits of floating-point numbers\n",
    "\n",
    "- **Largest** `Float64` $= \\left(2 - 2^{-52}\\right) \\times 2^{1023} \\approx 2 \\times 10^{308}$\n",
    "- **Smallest positive normalized** `Float64` $= 2^{-1022} \\approx 2 \\times 10^{-308}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7976931348623157e308"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = realmax(Float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"0111111111101111111111111111111111111111111111111111111111111111\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bits(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2250738585072014e-308"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = realmin(Float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"0000000000010000000000000000000000000000000000000000000000000000\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bits(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IEEE floating-point standard also allows **de-normalized** numbers that are smaller than `realmin(Float64)`. De-normalized floats are represented by $e = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2.2250738585072014e-308 = 2.0^(-1022)\n",
      " 1.1125369292536007e-308 = 2.0^(-1023)\n",
      " 5.5626846462680035e-309 = 2.0^(-1024)\n",
      " 2.7813423231340017e-309 = 2.0^(-1025)\n",
      " 1.3906711615670009e-309 = 2.0^(-1026)\n",
      " 6.9533558078350043e-310 = 2.0^(-1027)\n",
      " 3.4766779039175022e-310 = 2.0^(-1028)\n",
      " 1.7383389519587511e-310 = 2.0^(-1029)\n",
      " 8.6916947597937554e-311 = 2.0^(-1030)\n",
      " 4.3458473798968777e-311 = 2.0^(-1031)\n",
      " 2.1729236899484389e-311 = 2.0^(-1032)\n",
      " 1.0864618449742194e-311 = 2.0^(-1033)\n",
      " 5.4323092248710971e-312 = 2.0^(-1034)\n",
      " 2.7161546124355486e-312 = 2.0^(-1035)\n",
      " 1.3580773062177743e-312 = 2.0^(-1036)\n",
      " 6.7903865310888714e-313 = 2.0^(-1037)\n",
      " 3.3951932655444357e-313 = 2.0^(-1038)\n",
      " 1.6975966327722179e-313 = 2.0^(-1039)\n",
      " 8.4879831638610893e-314 = 2.0^(-1040)\n",
      " 4.2439915819305446e-314 = 2.0^(-1041)\n",
      " 2.1219957909652723e-314 = 2.0^(-1042)\n",
      " 1.0609978954826362e-314 = 2.0^(-1043)\n",
      " 5.3049894774131808e-315 = 2.0^(-1044)\n",
      " 2.6524947387065904e-315 = 2.0^(-1045)\n",
      " 1.3262473693532952e-315 = 2.0^(-1046)\n",
      " 6.6312368467664760e-316 = 2.0^(-1047)\n",
      " 3.3156184233832380e-316 = 2.0^(-1048)\n",
      " 1.6578092116916190e-316 = 2.0^(-1049)\n",
      " 8.2890460584580950e-317 = 2.0^(-1050)\n",
      " 4.1445230292290475e-317 = 2.0^(-1051)\n",
      " 2.0722615146145237e-317 = 2.0^(-1052)\n",
      " 1.0361307573072619e-317 = 2.0^(-1053)\n",
      " 5.1806537865363094e-318 = 2.0^(-1054)\n",
      " 2.5903268932681547e-318 = 2.0^(-1055)\n",
      " 1.2951634466340773e-318 = 2.0^(-1056)\n",
      " 6.4758172331703867e-319 = 2.0^(-1057)\n",
      " 3.2379086165851934e-319 = 2.0^(-1058)\n",
      " 1.6189543082925967e-319 = 2.0^(-1059)\n",
      " 8.0947715414629834e-320 = 2.0^(-1060)\n",
      " 4.0473857707314917e-320 = 2.0^(-1061)\n",
      " 2.0236928853657458e-320 = 2.0^(-1062)\n",
      " 1.0118464426828729e-320 = 2.0^(-1063)\n",
      " 5.0592322134143646e-321 = 2.0^(-1064)\n",
      " 2.5296161067071823e-321 = 2.0^(-1065)\n",
      " 1.2648080533535912e-321 = 2.0^(-1066)\n",
      " 6.3240402667679558e-322 = 2.0^(-1067)\n",
      " 3.1620201333839779e-322 = 2.0^(-1068)\n",
      " 1.5810100666919889e-322 = 2.0^(-1069)\n",
      " 7.9050503334599447e-323 = 2.0^(-1070)\n",
      " 3.9525251667299724e-323 = 2.0^(-1071)\n",
      " 1.9762625833649862e-323 = 2.0^(-1072)\n",
      " 9.8813129168249309e-324 = 2.0^(-1073)\n",
      " 4.9406564584124654e-324 = 2.0^(-1074)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0,-1075)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compute the smallest Float64 that is not zero\n",
    "\n",
    "e = -1022\n",
    "x = 2.0^e\n",
    "\n",
    "while x != 0.0\n",
    "    @printf \"%24.16e = 2.0^(%5d)\\n\" x e\n",
    "    x /= 2.0\n",
    "    e -= 1\n",
    "end\n",
    "\n",
    "x, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.0e-324,0.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.0^-1074, 2.0^-1075"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore:\n",
    "\n",
    "- **Smallest positive de-normalized** `Float64` $= 2^{-1074} \\approx 5 \\times 10^{-324}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"0000000000000000000000000000000000000000000000000000000000000001\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bits(2.0^-1074)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other special floats\n",
    "\n",
    "- `0.0` and `-0.0`: $$e_{10} \\cdots e_0 = 0 \\cdots 0 \\quad \\text{and} \\quad f_1 \\cdots f_{52} = 0 \\cdots 0$$\n",
    "- `Inf` and `-Inf`: $$e_{10} \\cdots e_0 = 1 \\cdots 1 \\quad \\text{and} \\quad f_1 \\cdots f_{52} = 0 \\cdots 0$$\n",
    "- `NaN` (not-a-number): $$e_{10} \\cdots e_0 = 1 \\cdots 1 \\quad \\text{and} \\quad f_1 \\cdots f_{52} \\neq 0$$\n",
    "\n",
    "From [Julia Manual: Mathematical Operations and Elementary Functions](http://julia.readthedocs.org/en/latest/manual/mathematical-operations/):\n",
    "\n",
    "- `Inf` is equal to itself and greater than everything else except `NaN`.\n",
    "- `-Inf` is equal to itself and less then everything else except `NaN`.\n",
    "- `NaN` is not equal to, not less than, and not greater than anything, including itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"0000000000000000000000000000000000000000000000000000000000000000\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bits(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1000000000000000000000000000000000000000000000000000000000000000\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bits(-0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"0111111111110000000000000000000000000000000000000000000000000000\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bits(Inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1111111111110000000000000000000000000000000000000000000000000000\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bits(-Inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"0111111111111000000000000000000000000000000000000000000000000000\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bits(NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0*0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1.0*0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inf"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0/0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-Inf"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1.0/0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0/Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1.0/Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0/0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.0 < 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0e-308"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0/-1e308"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine epsilon `eps(Float64)` and the unit roundoff $\\eta$\n",
    "\n",
    "- `1.0 + eps(Float64)` is the first `Float64` that is larger than `1.0`\n",
    "\n",
    "$$\\mathtt{eps(Float64)} = 2^{-52} \\approx 2.2 \\times 10^{-16}$$\n",
    "\n",
    "- $\\eta = $ `eps(Float64)/2.0` is the largest possible relative error due to roundoff\n",
    "\n",
    "$$\\eta = 2^{-53} \\approx 1.1 \\times 10^{-16}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-16"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps(Float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 + eps(Float64) > 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 + eps(Float64)/2.0 == 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roundoff error example\n",
    "\n",
    "Suppose we are using a base-10 floating-point system with 4 significant digits, using `RoundNearest`:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\left( 1.112 \\times 10^1 \\right) \\times \\left( 1.112 \\times 10^2 \\right)\n",
    "& = 1.236544 \\times 10^3 \\\\\n",
    "& \\rightarrow 1.237 \\times 10^3 = 1237\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "The absolute error is $1237 - 1236.544 = 0.456$.\n",
    "\n",
    "The relative error is $$\\frac{0.456}{1236.544} \\approx 0.0004 = 0.04 \\%$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003687697324155064"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.456/1236.544"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <matplotlib.figure.Figure object at 0x118991e90>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PyObject <matplotlib.text.Text object at 0x118adfc50>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the effect of roundoff error\n",
    "\n",
    "η = eps(Float32)/2.0         # Compute the unit roundoff for Float32\n",
    "\n",
    "x = linspace(-10, 10, 10000)   # 1000-element Array{Float64,1} from -10 to 10\n",
    "y = float32(x)               # Convert x to Float32 and su\n",
    "abserr = abs(y - x)          # Compute the absolute roundoff errors\n",
    "relerr = abserr./abs(x)      # Compute the relative roundoff errors\n",
    "\n",
    "using PyPlot  # Loading PyPlot takes some time -- be patient\n",
    "subplot(1, 2, 1)\n",
    "plot(x, abserr)\n",
    "axis([minimum(x), maximum(x), minimum(abserr), maximum(abserr)])\n",
    "title(\"absolute error\")\n",
    "\n",
    "subplot(1, 2, 2)\n",
    "plot(x, relerr)\n",
    "plot(x, η*ones(x), \"r\")\n",
    "axis([minimum(x), maximum(x), minimum(abserr), maximum(abserr)])\n",
    "title(\"relative error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base.with_rounding(f::Function, T, mode)\n",
      "\n",
      "   Change the rounding mode of floating point type \"T\" for the\n",
      "   duration of \"f\". It is logically equivalent to:\n",
      "\n",
      "      old = get_rounding(T)\n",
      "      set_rounding(T, mode)\n",
      "      f()\n",
      "      set_rounding(T, old)\n",
      "\n",
      "   See \"get_rounding\" for available rounding modes.\n"
     ]
    }
   ],
   "source": [
    "?with_rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base.get_rounding(T)\n",
      "\n",
      "   Get the current floating point rounding mode for type \"T\". Valid\n",
      "   modes are \"RoundNearest\", \"RoundToZero\", \"RoundUp\",\n",
      "   \"RoundDown\", and \"RoundFromZero\" (\"BigFloat\" only).\n"
     ]
    }
   ],
   "source": [
    "?get_rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RoundingMode(0),RoundingMode(1),RoundingMode(2),RoundingMode(3),RoundingMode(4))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RoundNearest, RoundToZero, RoundUp, RoundDown, RoundFromZero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RoundingMode(0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rounding(Float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the default rounding mode is `RoundNearest` (round to the nearest floating-point number). This implies that\n",
    "\n",
    "$$ \\frac{|x - \\mathrm{fl}(x)|}{|x|} \\leq \\frac{1}{2} 2^{-52} = \\eta.$$\n",
    "\n",
    "If `RoundToZero` is used (a.k.a. **chopping**), then\n",
    "\n",
    "$$ \\frac{|x - \\mathrm{fl}(x)|}{|x|} \\leq 2^{-52} = 2 \\eta.$$\n",
    "\n",
    "`RoundNearest` is used since it produces smaller roundoff errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base.set_rounding(T, mode)\n",
      "\n",
      "   Set the rounding mode of floating point type \"T\". Note that this\n",
      "   may affect other types, for instance changing the rounding mode of\n",
      "   \"Float64\" will change the rounding mode of \"Float32\". See\n",
      "   \"get_rounding\" for available modes\n"
     ]
    }
   ],
   "source": [
    "?set_rounding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roundoff error accumulation\n",
    "\n",
    "When performing arithmetic operations on floats, extra **guard digits** are used to ensure **exact rounding**. This guarantees that the relative error of a floating-point operation (**flop**) is small. More precisely, for floating-point numbers $x$ and $y$, we have\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\mathrm{fl}(x \\pm y) &= (x \\pm y)(1 + \\varepsilon_1) \\\\\n",
    "\\mathrm{fl}(x \\times y) &= (x \\times y)(1 + \\varepsilon_2) \\\\\n",
    "\\mathrm{fl}(x \\div y) &= (x \\div y)(1 + \\varepsilon_3) \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "where $|\\varepsilon_i| \\leq \\eta$, for $i = 1,2,3$, where $\\eta$ is the unit roundoff.\n",
    "\n",
    "Although the relative error of each flop is small, it is possible to have the roundoff error accumulate and create significant error in the final result. If $E_n$ is the error after $n$ flops, then:\n",
    "\n",
    "- **linear roundoff error accumulation** is when $E_n \\approx c_0 n E_0$\n",
    "- **exponential roundoff error accumulation** is when $E_n \\approx c_1^n E_0$, for some $c_1 > 1$\n",
    "\n",
    "In general, linear roundoff error accumulation is unavoidable. On the other hand, exponential roundoff error accumulation is not acceptable and is an indication of an **unstable algorithm**. (See Example 1.6 in Ascher-Greif for an example of exponential roundoff error accumulation, and see Exercise 5 in Section 1.4 for a numerically stable method to accomplish the same task.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General advice\n",
    "\n",
    "1. Adding $x + y$ when $|x| \\gg |y|$ can cause the information in $y$ to be 'lost' in the summation (see example below).\n",
    "\n",
    "2. Dividing by very small numbers or multiplying by very large numbers can greatly **magnify error** (as we saw when approximating a derivative in Chapter 1).\n",
    "\n",
    "3. Subtracting numbers that are almost equal produces **cancellation error** (see example below).\n",
    "\n",
    "4. An **overflow** occurs when the result is too large in magnitude to be representable as a float. Result will become either `Inf` or `-Inf`. Overflows should be avoided (see example below).\n",
    "\n",
    "4. An **underflow** occurs when the result is too small in magnitude to be representable as a float. Result will become either `0.0` or `-0.0`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example (summation order)\n",
    "\n",
    "This next example shows that summation order can make a difference. We will compute\n",
    "\n",
    "$$\n",
    "s = \\sum_{n = 1}^{1,000,000} \\frac{1}{n}\n",
    "$$\n",
    "\n",
    "in two different ways: from largest to smallest and from smallest to largest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.357358 (badsum)\n",
      "14.392652 (goodsum)\n",
      "14.392727 (truesum)\n",
      "0.03536892 (badsum error)\n",
      "7.534027e-5 (goodsum error)\n"
     ]
    }
   ],
   "source": [
    "# We will use Float32 to emphasize the loss of accuracy.\n",
    "# Note:  Float32 should normally never be used.\n",
    "\n",
    "# Summing from largest to smallest:  n = 1, 2, ..., 1000000\n",
    "badsum = float32(0.0)\n",
    "for n = 1:1000000\n",
    "    badsum += float32(1/n)\n",
    "end\n",
    "println(badsum, \" (badsum)\")\n",
    "\n",
    "# Summing from smallest to largest:  n = 1000000, 999999, ..., 1\n",
    "goodsum = float32(0.0)\n",
    "for n = 1000000:-1:1\n",
    "    goodsum += float32(1/n)\n",
    "end\n",
    "println(goodsum, \" (goodsum)\")\n",
    "\n",
    "# The 'exact' answer using BigFloat extended precision (slow)\n",
    "s = big(0.0)\n",
    "for n = 1000000:-1:1\n",
    "    s += big(1/n)\n",
    "end\n",
    "truesum = float32(s)\n",
    "println(truesum, \" (truesum)\")\n",
    "\n",
    "println(abs(truesum - badsum), \" (badsum error)\")\n",
    "println(abs(truesum - goodsum), \" (goodsum error)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example (cancellation error)\n",
    "\n",
    "It is easy to show that \n",
    "\n",
    "$$\n",
    "\\ln\\left( x - \\sqrt{x^2-1} \\right) = -\\ln\\left( x + \\sqrt{x^2-1} \\right).\n",
    "$$\n",
    "\n",
    "Indeed,\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\ln\\left( x - \\sqrt{x^2-1} \\right) \n",
    "& = \\ln\\left( \\frac{x - \\sqrt{x^2-1}}{1} \\cdot \\frac{x + \\sqrt{x^2-1}}{x + \\sqrt{x^2-1}} \\right) \\\\\n",
    "& = \\ln\\left( \\frac{x^2 - \\left(x^2-1\\right)}{x + \\sqrt{x^2-1}} \\right) \\\\\n",
    "& = \\ln\\left( \\frac{1}{x + \\sqrt{x^2-1}} \\right) \\\\\n",
    "& = -\\ln\\left( x + \\sqrt{x^2-1} \\right). \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Which formula is more suitable for numerical computation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-14.50865012405984 (badres)\n",
      "-14.508657738523969 (goodres)\n",
      "-14.508657738523969 (trueres)\n",
      "5.248220935854038e-7 (badres error)\n",
      "0.0 (goodres error)\n"
     ]
    }
   ],
   "source": [
    "x = 1e6\n",
    "\n",
    "badres  =  log(x - sqrt(x^2 - 1))\n",
    "goodres = -log(x + sqrt(x^2 - 1))\n",
    "\n",
    "x = big(x)\n",
    "trueres = float64(-log(x + sqrt(x^2 - 1)))\n",
    "\n",
    "println(badres, \" (badres)\")\n",
    "println(goodres, \" (goodres)\")\n",
    "println(trueres, \" (trueres)\")\n",
    "\n",
    "println(abs(badres - trueres)/abs(trueres), \" (badres error)\")\n",
    "println(abs(goodres - trueres)/abs(trueres), \" (goodres error)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example (avoiding overflow)\n",
    "\n",
    "Overflow is possible when squaring a large number. This needs to be avoided when computing the Euclidean norm (a.k.a. the $\\ell_2$-norm) of a vector $x$:\n",
    "\n",
    "$$\n",
    "\\|x\\|_2 = \\sqrt{x_1^2 + x_2^2 + \\cdots + x_n^2}.\n",
    "$$\n",
    "\n",
    "If some $x_i$ is very large, it is possible that $x_i^2$ will overflow, causing the final result to be `Inf`. We can avoid this as follows.\n",
    "\n",
    "Let \n",
    "$$\\bar{x} = \\max_{i=1:n} |x_i|.$$\n",
    "Then\n",
    "$$\n",
    "\\|x\\|_2 = \\bar{x} \\sqrt{\\left(\\frac{x_1}{\\bar{x}}\\right)^2 + \\left(\\frac{x_2}{\\bar{x}}\\right)^2 + \\cdots + \\left(\\frac{x_n}{\\bar{x}}\\right)^2}.\n",
    "$$\n",
    "Since $|x_i/\\bar{x}| \\leq 1$ for all $i$, no overflow will occur. Underflow may occur, but this is harmless.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "badres = Inf\n",
      "goodres = 5.603757056896095e201\n",
      "norm(x) = 5.603757056896095e201\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "x = 10e200*rand(n)\n",
    "\n",
    "# Overflow occurs\n",
    "s = 0.0\n",
    "for i = 1:n\n",
    "    s += x[i]^2\n",
    "end\n",
    "badres = sqrt(s)\n",
    "println(\"badres = \", badres)\n",
    "\n",
    "# Overflow is avoided\n",
    "xbar = maximum(abs(x))\n",
    "xscaled = x/xbar\n",
    "s = 0.0\n",
    "for i = 1:n\n",
    "    s += xscaled[i]^2\n",
    "end\n",
    "goodres = xbar*sqrt(s)\n",
    "println(\"goodres = \", goodres)\n",
    "\n",
    "# Use the built-in norm function to check\n",
    "println(\"norm(x) = \", norm(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.11",
   "language": "julia",
   "name": "julia-0.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
